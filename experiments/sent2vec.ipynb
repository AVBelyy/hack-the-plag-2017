{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import csv\n",
    "import regex\n",
    "import pickle\n",
    "import pymystem3\n",
    "import itertools\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from lxml import etree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "token_regexp = regex.compile(\"(?u)\\\\b(\\\\p{L}+|\\d+)\\\\b\")\n",
    "\n",
    "def tokenize(text):\n",
    "    return token_regexp.findall(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "stemmer = pymystem3.Mystem()\n",
    "\n",
    "add_unparsed = True\n",
    "gr_regexp = regex.compile(\"[^\\w]\")\n",
    "\n",
    "def lemmatize(tokens):\n",
    "    lemmas = []\n",
    "    tokens_str = \" \".join(tokens)\n",
    "    for res in stemmer.analyze(tokens_str):\n",
    "        if res.get(\"analysis\"):\n",
    "            info = res[\"analysis\"][0]\n",
    "            #stem_pos, *_ = gr_regexp.split(info[\"gr\"].upper())\n",
    "            #lemmas.append(\"%s_%s\" % (info[\"lex\"], mystem_to_uni_map.get(stem_pos, \"X\")))\n",
    "            lemmas.append(info[\"lex\"].strip())\n",
    "        elif add_unparsed:\n",
    "            lemmas.append(res[\"text\"].strip())\n",
    "    return list(filter(None, lemmas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data_dir = \"../data/text_alignment/\"\n",
    "task_name = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 5min 3s, sys: 21.8 s, total: 5min 25s\n",
      "Wall time: 25min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "files_sentences_ids = {}\n",
    "sents_cnt = 0\n",
    "\n",
    "paths = collections.OrderedDict()\n",
    "with open(data_dir + \"tasks/%s/pairs\" % task_name) as fin:\n",
    "    for line in fin:\n",
    "        susp_name, src_name = line.strip().split()\n",
    "        paths[\"susp/\" + susp_name] = 1\n",
    "        paths[\"src/\" + src_name] = 1\n",
    "paths = list(paths.keys())\n",
    "\n",
    "with open(\"dialog.sent2vec.train.txt\", \"w\") as fout:\n",
    "    for path in tqdm_notebook(paths):\n",
    "        need_to_continue = False\n",
    "        lines = []\n",
    "        with open(data_dir + path) as file:\n",
    "            for line in file:\n",
    "                line = line.strip().lower()\n",
    "                tokens = tokenize(line)\n",
    "                lines.append(tokens)\n",
    "        files_sentences_ids[path] = []\n",
    "        for i, line in enumerate(lines):\n",
    "            lemmas = lemmatize(line)\n",
    "            if lemmas:\n",
    "                fout.write(\"%s\\n\" % \" \".join(lemmas))\n",
    "                files_sentences_ids[path].append((sents_cnt, i))\n",
    "                sents_cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 33M words\n",
      "Number of words:  307125\n",
      "Number of labels: 0\n",
      "terminate called after throwing an instance of 'std::bad_alloc'\n",
      "  what():  std::bad_alloc\n",
      "CPU times: user 227 ms, sys: 57 ms, total: 284 ms\n",
      "Wall time: 7.18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "!./sent2vec sent2vec -input dialog.sent2vec.train.txt -output dialog.sent2vec -minCount 2 \\\n",
    "                     -dim 100 -wordNgrams 2 -epoch 50 -lr 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## How well train set is fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 4.99 s, sys: 377 ms, total: 5.36 s\n",
      "Wall time: 24.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "sentences_cnt = 0\n",
    "sentences_pairs_list = []\n",
    "\n",
    "with open(\"train_texts.csv\") as csv_file, open(\"sent2vec.test.txt\", \"w\") as out_test_file:\n",
    "    header = csv_file.readline().strip().split(\",\")\n",
    "    header[0] = \"id\"\n",
    "    csv_reader = csv.DictReader(csv_file, header)\n",
    "    for row in tqdm_notebook(csv_reader):\n",
    "        susp_text = lemmatize(tokenize(row[\"suspicious_text\"].strip().lower()))\n",
    "        src_text = lemmatize(tokenize(row[\"source_text\"].strip().lower()))\n",
    "        out_test_file.write(\"%s\\n%s\\n\" % (\" \".join(susp_text), \" \".join(src_text)))\n",
    "        sentences_pairs_list.append((sentences_cnt, sentences_cnt + 1))\n",
    "        sentences_cnt += 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.42 s, sys: 163 ms, total: 1.59 s\n",
      "Wall time: 4.71 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "sentences_list = []\n",
    "\n",
    "sv_out = !./sent2vec print-sentence-vectors sent2vec.bin < sent2vec.test.txt\n",
    "for line in sv_out:\n",
    "    sentences_list.append(np.array(list(map(float, line.strip().split(\" \")))))\n",
    "del sv_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "negative_sample_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1min 14s, sys: 0 ns, total: 1min 14s\n",
      "Wall time: 20.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "clf_train = []\n",
    "results_list = []\n",
    "\n",
    "for sentence_pair in tqdm_notebook(sentences_pairs_list):\n",
    "    question_id = sentence_pair[0]\n",
    "    question = sentences_list[question_id]\n",
    "    positive_sample_id = sentence_pair[1]\n",
    "    positive_sample = sentences_list[positive_sample_id]\n",
    "    negative_samples_ids = set()\n",
    "    while True:\n",
    "        sample_id = np.random.choice(len(sentences_list))\n",
    "        if sample_id not in negative_samples_ids and sample_id not in sentence_pair:\n",
    "            negative_samples_ids.add(sample_id)\n",
    "        if len(negative_samples_ids) == negative_sample_size:\n",
    "            break\n",
    "    negative_samples = list(map(sentences_list.__getitem__, negative_samples_ids))\n",
    "    dists = 1 - cosine_similarity([question], [positive_sample] + negative_samples)[0]\n",
    "    ranks = sorted(range(len(dists)), key=dists.__getitem__)\n",
    "    res = ranks.index(0)\n",
    "    results_list.append(res)\n",
    "    clf_train.append((dists[ranks[0]], res == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean ranking: 0.847\n",
      "nDCG@ 1: 0.957 | Hits@ 1: 0.957\n",
      "nDCG@ 5: 0.969 | Hits@ 5: 0.978\n",
      "nDCG@10: 0.970 | Hits@10: 0.983\n"
     ]
    }
   ],
   "source": [
    "ks = [1, 5, 10]\n",
    "results_all_ranks = np.array(results_list)\n",
    "\n",
    "print(\"Mean ranking: %.3f\" % np.mean(results_all_ranks))\n",
    "\n",
    "for k in ks:\n",
    "    ndcg = np.mean(1 / np.log2(np.where(results_all_ranks <= k - 1, results_all_ranks, np.inf) + 2))\n",
    "    hits = len(results_all_ranks[results_all_ranks <= k - 1]) / len(results_all_ranks)\n",
    "    print(\"nDCG@%2d: %.3f | Hits@%2d: %.3f\" % (k, ndcg, k, hits))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def show_texts(plag_id):\n",
    "    obj = test_df.loc[plag_id]\n",
    "    print(\"Plagiat type:\", obj[\"obfuscation\"])\n",
    "    print(\"susp/\" + obj[\"suspicious_path\"] + \" : \" + repr(obj[\"suspicious_text\"]))\n",
    "    print(\"src/\"+ obj[\"source_path\"] + \" : \" + repr(obj[\"source_text\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## How well text alignment performs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 266 ms, sys: 19 ms, total: 285 ms\n",
      "Wall time: 9.95 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "!./sent2vec print-sentence-vectors sent2vec.bin < sent2vec.train.txt > vectors.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.71 s, sys: 195 ms, total: 4.91 s\n",
      "Wall time: 4.91 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "all_vectors = []\n",
    "\n",
    "with open(\"vectors.txt\") as fin:\n",
    "    for line in fin:\n",
    "        all_vectors.append(list(map(float, line.strip().split(\" \"))))\n",
    "\n",
    "all_vectors = np.array(all_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "clf_train_df = pd.DataFrame(clf_train, columns=[\"sent2vec_dist\", \"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f128a4592b0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nS64AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f128957b0b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf_train_df[clf_train_df[\"y\"] == 1][\"sent2vec_dist\"].hist(color=\"g\", range=(0.1, 0.7))\n",
    "clf_train_df[clf_train_df[\"y\"] == 0][\"sent2vec_dist\"].hist(color=\"r\", range=(0.1, 0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 3.63 s, sys: 219 ms, total: 3.85 s\n",
      "Wall time: 1.23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "threshold = 0.2\n",
    "detections = []\n",
    "\n",
    "for line in tqdm_notebook(open(\"tasks/pairs\")):\n",
    "    all_metrics = []\n",
    "    ijs = []\n",
    "    ds = []\n",
    "    susp_file, src_file = line.split()\n",
    "    susp_path = os.path.join(\"susp\", susp_file)\n",
    "    src_path = os.path.join(\"src\", src_file)\n",
    "    susp_lens = np.cumsum([0] + list(map(len, open(susp_path).readlines())))\n",
    "    src_lens = np.cumsum([0] + list(map(len, open(src_path).readlines())))\n",
    "    susp_ids = files_sentences_ids[susp_path]\n",
    "    src_ids = files_sentences_ids[src_path]\n",
    "    susp_vectors = all_vectors[min(susp_ids)[0]:max(susp_ids)[0] + 1]\n",
    "    src_vectors = all_vectors[min(src_ids)[0]:max(src_ids)[0] + 1]\n",
    "    sim = 1 - cosine_similarity(susp_vectors, src_vectors)\n",
    "    for i2, j2 in zip(*np.where(sim < threshold)): # TODO: rework this idea completely !!!\n",
    "        i = susp_ids[i2][1]\n",
    "        j = src_ids[j2][1]\n",
    "        #print(i, j)\n",
    "        #print(sentences[susp_path][i])\n",
    "        #print(sentences[src_path][j])\n",
    "        #print(sim[i2][j2])\n",
    "        ds.append(((src_lens[j], src_lens[j + 1] - 1), (susp_lens[i], susp_lens[i + 1] - 1)))\n",
    "    detections.append(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 225 ms, sys: 2 ms, total: 227 ms\n",
      "Wall time: 226 ms\n"
     ]
    }
   ],
   "source": [
    "%time pickle.dump(detections, open(\"detections.dump\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "widgets": {
   "state": {
    "318d3832997a4439a38aa512518d4abf": {
     "views": [
      {
       "cell_index": 6
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
